[TR]<br>

Doç. Dr. İlker Köse (Bitirme Projesi Danışmanı) ve Dr. Öğr. Üyesi Salih Sarp  (TÜBİTAK Projesi Danışmanı) rehberliğinde yürütülen, 
TÜBİTAK 2209-A üniversite öğrencileri araştırma projeleri destekleme programı kapsamında başvurusu yapılmış bir çalışmadır. 
Proje, derin öğrenme modellerinin düşmanca saldırılar karşısındaki yapısal zafiyetlerini sistematik olarak inceleyerek , 
doğruluk ve sağlamlık arasındaki kritik ödünleşim (trade-off) dengesini ampirik verilerle ortaya koymaktadır. 
Çalışmanın temel özgünlüğü, modelin performansının belirli bir gürültü eşiğinden sonra hızla düştüğü noktayı belirleyen 
"Kararsızlık Bölgesi" adlı metriği literatüre kazandırmasıdır. Sistematik FGSM ve PGD saldırı simülasyonlarından elde edilen nicel veriler , 
makine öğrenimi güvenlik operasyonları disiplinine uygun olarak geliştirilen Robuspect adlı Güvenilirlik Analiz Gösterge Paneli aracılığıyla ürünleştirilecektir.
<br>
<img width="3366" height="4759" alt="000" src="https://github.com/user-attachments/assets/faa93053-8ce9-49e5-8cc5-ae95d94d9bca" />

<br>
Güvenilir ve siber dayanıklılığı yüksek yerli yapay zekâ sistemleri geliştirme yolculuğumuza dair detaylar için repositorye göz atınız. <br>
<br>
<br>

[EN]<br>
The research project titled "CNN Tabanlı Yapay Zekâ Sistemlerinde Robustness Spektrumunun Haritalandırılması: FGSM ve PGD Karşılaştırmalı Çalışması ile Nicel Güvenilirlik Analiz Platformu Geliştirilmesi"  is conducted under the supervision of Assoc. Prof. İlker Köse (Senior Project Advisor) and Asst. Prof. Salih Sarp  (TÜBİTAK Project Advisor), and has been submitted to the TÜBİTAK 2209-A research grant program. The project systematically investigates the structural vulnerabilities of deep learning models against adversarial attacks , providing an empirical analysis of the critical trade-off between accuracy and robustness. The primary novelty of the work lies in the introduction of the "Instability Region" metric, which quantitatively maps a model's reliability boundaries. Data obtained from systematic FGSM and PGD attack simulations will be productized into a Reliability Analysis Dashboard named Robuspect, aligned with MLSecOps (Machine Learning Security Operations) principles.
<br>
<img width="3366" height="4759" alt="001" src="https://github.com/user-attachments/assets/670fe41d-5c25-46e9-9ad9-db1c3055eb02" />

<br>
Check out the repository for insights into our mission of building reliable and cyber-resilient domestic AI solutions.
